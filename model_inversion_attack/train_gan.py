# Common imports
import os
import torch
import numpy as np
from tqdm import tqdm

# Dataset
from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision.datasets import EMNIST

# Data Visualization
import matplotlib.pyplot as plt

# Model
from torch import nn
from torch.nn import Module, Sequential
from torch.nn import Conv2d, ConvTranspose2d
from torch.nn import BatchNorm2d, ReLU, LeakyReLU, Tanh


# ENV Constants
DEVICE = "cpu"
IMG_DIMS = 28

# Model Constants
ZDIM = 32
HDIM = 32
IMG_CHANNELS = 1

# Training Constants
LR = 2e-4
EPOCHS = 20                           # Change with respect to your hardware
beta_1 = 0.5
C_LAMBDA = 10
beta_2 = 0.999
BATCH_SIZE = 16
CRITIC_STEPS = 5
DISPLAY_STEP = 500

# Reproducibility
np.random.seed(42)
torch.manual_seed(42)



class Generator(Module):
    """
    Generator for a Spectral Normalization Generative Adversarial Network (SN GAN).

    Parameters:
    - zdims (int): Dimensionality of the input noise vector.
    - hdims (int): Dimensionality of the hidden layers in the generator.
    - img_channels (int): Number of channels in the output synthesized images.

    Attributes:
    - zdims (int): Dimensionality of the input noise vector.
    - generator (Sequential): Sequential model representing the generator architecture.
    """

    def __init__(self, zdims: int = ZDIM, hdims: int = HDIM, img_channels: int = IMG_CHANNELS):
        """
        Initializes the Generator.

        Args:
        - zdims (int): Dimensionality of the input noise vector.
        - hdims (int): Dimensionality of the hidden layers in the generator.
        - img_channels (int): Number of channels in the output synthesized images.
        """

        super(Generator, self).__init__()

        self.zdims = zdims
        self.generator = Sequential(
            self.generator_block(ZDIM, HDIM),
            self.generator_block(HDIM, HDIM * 2, kernel_size=4, stride=1),
            self.generator_block(HDIM * 2, HDIM * 4),
            self.generator_block(HDIM * 4, img_channels, kernel_size=4, output_layer=True),
        )

    def generator_block(self, input_dims: int, output_dims: int, kernel_size: int = 3, stride: int = 2, output_layer: bool = False):
        """
        Defines a generator block.

        Args:
        - input_dims (int): Dimensionality of the input to the block.
        - output_dims (int): Dimensionality of the output from the block.
        - kernel_size (int): Size of the convolutional kernel.
        - stride (int): Stride of the convolutional operation.
        - output_layer (bool): Indicates whether this block is the output layer.

        Returns:
        - Sequential: Generator block as a Sequential model.
        """

        if output_layer:
            return Sequential(
                ConvTranspose2d(input_dims, output_dims, kernel_size, stride),
                Tanh()
            )
        else:
            return Sequential(
                ConvTranspose2d(input_dims, output_dims, kernel_size, stride),
                BatchNorm2d(output_dims),
                ReLU(inplace=True)
            )

    def forward(self, noise):
        """
        Forward pass of the generator.

        Args:
        - noise (Tensor): Input noise tensor.

        Returns:
        - Tensor: Synthesized images.
        """

        noise = noise.view(len(noise), self.zdims, 1, 1)
        synthesized_images = self.generator(noise)

        return synthesized_images
    
    
def generate_noise(n_samples: int, z_dims: int = ZDIM, device: str = DEVICE) -> torch.Tensor:
    """
    Generate a random noise vector for GAN input.

    Args:
    - n_samples (int): Number of noise vectors to generate.
    - z_dims (int): Dimensionality of the noise vector.
    - device (str): Device to place the generated noise tensor (default is DEVICE).

    Returns:
    - torch.Tensor: Random noise vector of shape (n_samples, z_dims).
    """
    return torch.randn(n_samples, z_dims, device=device)

def show_generations(generations, n_rows=1, n_cols=1, figsize=(8, 5), title=None, save_loc=None):
    """
    Display a grid of synthetic images generated by the generator.

    Args:
        generations (torch.Tensor): A tensor containing synthetic image data.
        n_rows (int): Number of rows in the grid.
        n_cols (int): Number of columns in the grid.
        figsize (tuple): Size of the figure (default is (8, 5)).
        title (str): Title for the figure (default is None).
        save_loc (str): File path to save the figure (default is None).

    """
    synthetic_images = generations.view(-1, IMG_DIMS, IMG_DIMS, IMG_CHANNELS).detach().cpu()

    plt.figure(figsize=figsize)
    plt.suptitle("Synthetic Images" if title is None else title)

    for index in range(n_rows * n_cols):
        plt.subplot(n_rows, n_cols, index+1)
        plt.imshow(synthetic_images[index], cmap='gray')
        plt.axis('off')

    if save_loc is not None:
        if not os.path.exists(os.path.dirname(save_loc)):
            os.makedirs(os.path.dirname(save_loc))
        plt.savefig(save_loc)

    plt.show()

class Critic(Module):
    def __init__(self, hdims:int =HDIM, img_channels:int=IMG_CHANNELS):
        """
        Initialize the Critic network.

        Args:
        - img_channels (int): Number of input channels (e.g., 1 for grayscale, 3 for RGB).
        - hdims (int): Number of channels in the first hidden layer.
        """
        super(Critic, self).__init__()

        self.critic = Sequential(
            self.critic_block(img_channels, hdims),
            self.critic_block(hdims, hdims * 2),
            self.critic_block(hdims * 2, 1, output_layer=True),
        )

    def critic_block(self, input_dims, output_dims, kernel_size=4, stride=2, output_layer=False):
        """
        Create a Critic block.

        Args:
        - input_dims (int): Number of input channels.
        - output_dims (int): Number of output channels.
        - kernel_size (int): Size of the convolutional kernel.
        - stride (int): Stride for the convolution operation.
        - output_layer (bool, optional): If True, only spectral normalization is applied, else batch normalization and LeakyReLU are added.

        Returns:
        - Sequential: A Critic block.
        """
        if output_layer:
            return Sequential(
                Conv2d(input_dims, output_dims, kernel_size, stride)
            )
        else:
            return Sequential(
                Conv2d(input_dims, output_dims, kernel_size, stride),
                BatchNorm2d(output_dims),
                LeakyReLU(0.2, inplace=True)
            )

    def forward(self, image):
        """
        Forward pass of the Critic network.

        Args:
        - image (torch.Tensor): The input image.

        Returns:
        - torch.Tensor: The Critic's prediction.
        """
        critic_pred = self.critic(image)
        return critic_pred.view(len(critic_pred), -1)
    
    
    
if __name__ == '__main__':
    # Initialize the generator
    generator = Generator().to(DEVICE)

    # Initialize generator optimizer
    generator_optim = torch.optim.Adam(params = generator.parameters(), lr = LR, betas = (beta_1, beta_2))

    # Initialize the critic
    critic = Critic().to(DEVICE)

    # Initialize critic optimizer
    critic_optim = torch.optim.Adam(params = critic.parameters(), lr = LR, betas = (beta_1, beta_2))
        
    # Normalize the weights of generator and critic
    def weights_init(m):
        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
            torch.nn.init.normal_(m.weight, 0.0, 0.02)
        if isinstance(m, nn.BatchNorm2d):
            torch.nn.init.normal_(m.weight, 0.0, 0.02)
            torch.nn.init.constant_(m.bias, 0)

    generator = generator.apply(weights_init)
    critic = critic.apply(weights_init)  
    
    transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
    ])

    dataloader = DataLoader(
        EMNIST("emnist","digits", download=True, transform=transform),
        batch_size=BATCH_SIZE,
        shuffle=True)
    
    def extract_gradients(critic: Module, real: torch.Tensor, fake: torch.Tensor, epsilon: torch.Tensor) -> torch.Tensor:
        """
        Extracts the gradients of the critic's output with respect to the pixels of mixed images.

        Parameters:
            critic (torch.nn.Module): The critic model.
            real (torch.Tensor): Real images.
            fake (torch.Tensor): Fake images.
            epsilon (float): Weighting factor for combining real and fake images in creating mixed images.

        Returns:
            torch.Tensor: Gradients of the critic's output with respect to the pixels of the mixed images.
        """
        # Create mixed images
        mixed_images = real * epsilon + fake * (1 - epsilon)

        # Get critic's scores on the mixed images
        mixed_scores = critic(mixed_images)

        # Compute gradients
        gradients = torch.autograd.grad(
            inputs=mixed_images,
            outputs=mixed_scores,
            grad_outputs=torch.ones_like(mixed_scores),
            create_graph=True,
            retain_graph=True
        )[0]

        return gradients
    
    def gradient_penalty(gradients: torch.Tensor) -> torch.Tensor:
        """
        Computes the gradient penalty based on the norm of the gradients.

        Parameters:
            gradients (torch.Tensor): Gradients of the critic's output with respect to the pixels.

        Returns:
            torch.Tensor: Computed gradient penalty.
        """
        # Reshape gradients for computation
        gradients = gradients.view(len(gradients), -1)

        # Calculate the L2 norm of gradients
        gradient_norm = gradients.norm(2, dim=1)

        # Compute the penalty term
        penalty = torch.mean((gradient_norm - 1) ** 2)

        return penalty
    
    # Updated generator Loss
def compute_generator_loss(critic_fake_pred):
    """
    Calculates the generator loss for a Wasserstein GAN.

    Parameters:
        critic_fake_pred (torch.Tensor): Critic's output for fake/generated samples.

    Returns:
        torch.Tensor: Generator loss.
    """
    return -1. * torch.mean(critic_fake_pred)

# Updated Critic Loss
def compute_critic_loss(crit_fake_pred, crit_real_pred, gp, c_lambda):
    """
    Calculates the critic loss for a Wasserstein GAN with Gradient Penalty.

    Parameters:
        crit_fake_pred (torch.Tensor): Critic's output for fake/generated samples.
        crit_real_pred (torch.Tensor): Critic's output for real samples.
        gp (torch.Tensor): Gradient penalty.
        c_lambda (float): Hyperparameter controlling the strength of the gradient penalty.

    Returns:
        torch.Tensor: Critic loss.
    """
    return torch.mean(crit_fake_pred) - torch.mean(crit_real_pred) + c_lambda * gp


if __name__ == "__main__":

    #  begin training
    dir = './img'
    # Start the training process
    for epoch in range(1, EPOCHS+ 1):

        # Record Losses
        CRITIC_LOSSES = []
        GENERATOR_LOSSES = []
        SSIM_SCORES = []

        # Load the data.
        step = 0
        for real, _ in tqdm(dataloader):

            # Current step configurations
            curr_batch_size = len(real)
            real_images = real.to(DEVICE)

            mean_iter_critic_loss = 0

            for _ in range(CRITIC_STEPS):

                # Updating the critic
                critic_optim.zero_grad()

                fake_images = generator(generate_noise(curr_batch_size))
                critic_fake_preds = critic(fake_images.detach())
                critic_real_preds = critic(real_images)

                epsilon = torch.rand(curr_batch_size, 1, 1, 1, device=DEVICE, requires_grad=True)
                gp = gradient_penalty(extract_gradients(critic, real_images, fake_images.detach(), epsilon))

                critic_loss = compute_critic_loss(critic_fake_preds, critic_real_preds, gp, C_LAMBDA)

                mean_iter_critic_loss += critic_loss.item() / CRITIC_STEPS

                critic_loss.backward(retain_graph=True)
                critic_optim.step()

            CRITIC_LOSSES += [mean_iter_critic_loss]

            # Update the generator
            generator_optim.zero_grad()
            fake_images = generator(generate_noise(curr_batch_size))
            critic_fake_pred = critic(fake_images)

            generator_loss = compute_generator_loss(critic_fake_pred)
            generator_loss.backward()
            generator_optim.step()

            GENERATOR_LOSSES += [generator_loss.item()]

            # if (step % 100 == 0):
            #     # score = ssim(real_images.detach(), fake_images.detach())
            #     SSIM_SCORES.append(score.detach().cpu())

            if (step % DISPLAY_STEP == 0):

                noise = generate_noise(25)
                synthetic_images = generator(noise)

                show_generations(
                    synthetic_images, 2, 3,
                    figsize=(8, 5),
                    title=f"Generated Images\nStep: {step} Epoch: {epoch}",
                    save_loc = f"./GeneratorImages/Epoch_{epoch}/synthetic_image_{step}.png"
                )

            step += 1

        # Render Learning curve after every epoch
        torch.save(critic.state_dict(), f'critic_epoch_{epoch}.pth')
        torch.save(generator.state_dict(), f'generator_epoch_{epoch}.pth')
        plt.title(f"Learning Curve\nEpoch: {epoch}")
        plt.plot(CRITIC_LOSSES, label='Critic')
        plt.plot(GENERATOR_LOSSES, label='Generator')
        plt.grid()
        plt.legend()
        plt.savefig(f"./{dir}/LC_Epoch{epoch}.png")
        plt.show()